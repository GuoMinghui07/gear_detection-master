{
  "best_metric": 0.029986755922436714,
  "best_model_checkpoint": "./results_patchtst/checkpoint-11800",
  "epoch": 6.504961411245866,
  "eval_steps": 200,
  "global_step": 11800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.027563395810363836,
      "grad_norm": 1.0070487260818481,
      "learning_rate": 4.986218302094818e-05,
      "loss": 2.2013,
      "step": 50
    },
    {
      "epoch": 0.05512679162072767,
      "grad_norm": 0.5533189177513123,
      "learning_rate": 4.9724366041896365e-05,
      "loss": 2.1957,
      "step": 100
    },
    {
      "epoch": 0.08269018743109151,
      "grad_norm": 3.7496232986450195,
      "learning_rate": 4.958654906284454e-05,
      "loss": 2.0626,
      "step": 150
    },
    {
      "epoch": 0.11025358324145534,
      "grad_norm": 6.5578203201293945,
      "learning_rate": 4.944873208379273e-05,
      "loss": 1.555,
      "step": 200
    },
    {
      "epoch": 0.11025358324145534,
      "eval_accuracy": 0.43096695226438186,
      "eval_loss": 1.4800716638565063,
      "eval_runtime": 67.4644,
      "eval_samples_per_second": 121.101,
      "eval_steps_per_second": 3.795,
      "step": 200
    },
    {
      "epoch": 0.1378169790518192,
      "grad_norm": 14.215147972106934,
      "learning_rate": 4.9310915104740906e-05,
      "loss": 1.3305,
      "step": 250
    },
    {
      "epoch": 0.16538037486218302,
      "grad_norm": 9.947566032409668,
      "learning_rate": 4.917309812568909e-05,
      "loss": 1.1177,
      "step": 300
    },
    {
      "epoch": 0.19294377067254687,
      "grad_norm": 16.240379333496094,
      "learning_rate": 4.903528114663727e-05,
      "loss": 0.8976,
      "step": 350
    },
    {
      "epoch": 0.2205071664829107,
      "grad_norm": 13.632458686828613,
      "learning_rate": 4.889746416758545e-05,
      "loss": 0.8314,
      "step": 400
    },
    {
      "epoch": 0.2205071664829107,
      "eval_accuracy": 0.6855569155446757,
      "eval_loss": 0.8563767075538635,
      "eval_runtime": 68.3175,
      "eval_samples_per_second": 119.589,
      "eval_steps_per_second": 3.747,
      "step": 400
    },
    {
      "epoch": 0.24807056229327454,
      "grad_norm": 17.729238510131836,
      "learning_rate": 4.875964718853363e-05,
      "loss": 0.7107,
      "step": 450
    },
    {
      "epoch": 0.2756339581036384,
      "grad_norm": 14.715883255004883,
      "learning_rate": 4.862183020948181e-05,
      "loss": 0.6936,
      "step": 500
    },
    {
      "epoch": 0.3031973539140022,
      "grad_norm": 9.425216674804688,
      "learning_rate": 4.8484013230429995e-05,
      "loss": 0.6152,
      "step": 550
    },
    {
      "epoch": 0.33076074972436603,
      "grad_norm": 23.18329620361328,
      "learning_rate": 4.834619625137817e-05,
      "loss": 0.5777,
      "step": 600
    },
    {
      "epoch": 0.33076074972436603,
      "eval_accuracy": 0.7549571603427172,
      "eval_loss": 0.6069625020027161,
      "eval_runtime": 70.1617,
      "eval_samples_per_second": 116.445,
      "eval_steps_per_second": 3.649,
      "step": 600
    },
    {
      "epoch": 0.35832414553472985,
      "grad_norm": 17.335025787353516,
      "learning_rate": 4.820837927232635e-05,
      "loss": 0.5185,
      "step": 650
    },
    {
      "epoch": 0.38588754134509373,
      "grad_norm": 15.06252670288086,
      "learning_rate": 4.8070562293274536e-05,
      "loss": 0.496,
      "step": 700
    },
    {
      "epoch": 0.41345093715545755,
      "grad_norm": 17.418954849243164,
      "learning_rate": 4.7932745314222714e-05,
      "loss": 0.4264,
      "step": 750
    },
    {
      "epoch": 0.4410143329658214,
      "grad_norm": 10.89528751373291,
      "learning_rate": 4.77949283351709e-05,
      "loss": 0.413,
      "step": 800
    },
    {
      "epoch": 0.4410143329658214,
      "eval_accuracy": 0.8707466340269278,
      "eval_loss": 0.38191646337509155,
      "eval_runtime": 69.1552,
      "eval_samples_per_second": 118.14,
      "eval_steps_per_second": 3.702,
      "step": 800
    },
    {
      "epoch": 0.4685777287761852,
      "grad_norm": 20.861839294433594,
      "learning_rate": 4.765711135611908e-05,
      "loss": 0.3648,
      "step": 850
    },
    {
      "epoch": 0.4961411245865491,
      "grad_norm": 26.269248962402344,
      "learning_rate": 4.751929437706726e-05,
      "loss": 0.3696,
      "step": 900
    },
    {
      "epoch": 0.523704520396913,
      "grad_norm": 8.60172176361084,
      "learning_rate": 4.738147739801544e-05,
      "loss": 0.3234,
      "step": 950
    },
    {
      "epoch": 0.5512679162072768,
      "grad_norm": 18.464553833007812,
      "learning_rate": 4.724366041896362e-05,
      "loss": 0.3113,
      "step": 1000
    },
    {
      "epoch": 0.5512679162072768,
      "eval_accuracy": 0.896328029375765,
      "eval_loss": 0.30499130487442017,
      "eval_runtime": 71.3049,
      "eval_samples_per_second": 114.578,
      "eval_steps_per_second": 3.59,
      "step": 1000
    },
    {
      "epoch": 0.5788313120176406,
      "grad_norm": 13.839154243469238,
      "learning_rate": 4.71058434399118e-05,
      "loss": 0.2993,
      "step": 1050
    },
    {
      "epoch": 0.6063947078280044,
      "grad_norm": 18.624267578125,
      "learning_rate": 4.696802646085998e-05,
      "loss": 0.2978,
      "step": 1100
    },
    {
      "epoch": 0.6339581036383682,
      "grad_norm": 18.332067489624023,
      "learning_rate": 4.6830209481808165e-05,
      "loss": 0.2808,
      "step": 1150
    },
    {
      "epoch": 0.6615214994487321,
      "grad_norm": 10.814569473266602,
      "learning_rate": 4.669239250275634e-05,
      "loss": 0.2795,
      "step": 1200
    },
    {
      "epoch": 0.6615214994487321,
      "eval_accuracy": 0.9361077111383109,
      "eval_loss": 0.21060475707054138,
      "eval_runtime": 69.8977,
      "eval_samples_per_second": 116.885,
      "eval_steps_per_second": 3.662,
      "step": 1200
    },
    {
      "epoch": 0.6890848952590959,
      "grad_norm": 19.985353469848633,
      "learning_rate": 4.655457552370452e-05,
      "loss": 0.2775,
      "step": 1250
    },
    {
      "epoch": 0.7166482910694597,
      "grad_norm": 16.755781173706055,
      "learning_rate": 4.6416758544652706e-05,
      "loss": 0.2225,
      "step": 1300
    },
    {
      "epoch": 0.7442116868798236,
      "grad_norm": 21.771026611328125,
      "learning_rate": 4.6278941565600884e-05,
      "loss": 0.2497,
      "step": 1350
    },
    {
      "epoch": 0.7717750826901875,
      "grad_norm": 47.891780853271484,
      "learning_rate": 4.614112458654907e-05,
      "loss": 0.238,
      "step": 1400
    },
    {
      "epoch": 0.7717750826901875,
      "eval_accuracy": 0.9230110159118727,
      "eval_loss": 0.216958150267601,
      "eval_runtime": 67.6422,
      "eval_samples_per_second": 120.783,
      "eval_steps_per_second": 3.785,
      "step": 1400
    },
    {
      "epoch": 0.7993384785005513,
      "grad_norm": 19.995365142822266,
      "learning_rate": 4.600330760749725e-05,
      "loss": 0.1875,
      "step": 1450
    },
    {
      "epoch": 0.8269018743109151,
      "grad_norm": 20.757308959960938,
      "learning_rate": 4.586549062844543e-05,
      "loss": 0.2216,
      "step": 1500
    },
    {
      "epoch": 0.8544652701212789,
      "grad_norm": 35.76682662963867,
      "learning_rate": 4.572767364939361e-05,
      "loss": 0.1771,
      "step": 1550
    },
    {
      "epoch": 0.8820286659316428,
      "grad_norm": 15.124726295471191,
      "learning_rate": 4.558985667034179e-05,
      "loss": 0.1964,
      "step": 1600
    },
    {
      "epoch": 0.8820286659316428,
      "eval_accuracy": 0.9438188494492044,
      "eval_loss": 0.1628349870443344,
      "eval_runtime": 72.7401,
      "eval_samples_per_second": 112.318,
      "eval_steps_per_second": 3.519,
      "step": 1600
    },
    {
      "epoch": 0.9095920617420066,
      "grad_norm": 27.77730369567871,
      "learning_rate": 4.545203969128997e-05,
      "loss": 0.187,
      "step": 1650
    },
    {
      "epoch": 0.9371554575523704,
      "grad_norm": 16.96688461303711,
      "learning_rate": 4.531422271223815e-05,
      "loss": 0.2083,
      "step": 1700
    },
    {
      "epoch": 0.9647188533627343,
      "grad_norm": 7.808625221252441,
      "learning_rate": 4.5176405733186336e-05,
      "loss": 0.1557,
      "step": 1750
    },
    {
      "epoch": 0.9922822491730982,
      "grad_norm": 14.94092082977295,
      "learning_rate": 4.5038588754134514e-05,
      "loss": 0.1972,
      "step": 1800
    },
    {
      "epoch": 0.9922822491730982,
      "eval_accuracy": 0.9412484700122399,
      "eval_loss": 0.1569160521030426,
      "eval_runtime": 69.6332,
      "eval_samples_per_second": 117.329,
      "eval_steps_per_second": 3.676,
      "step": 1800
    },
    {
      "epoch": 1.0198456449834619,
      "grad_norm": 9.78645133972168,
      "learning_rate": 4.490077177508269e-05,
      "loss": 0.195,
      "step": 1850
    },
    {
      "epoch": 1.0474090407938257,
      "grad_norm": 20.821340560913086,
      "learning_rate": 4.476295479603087e-05,
      "loss": 0.1553,
      "step": 1900
    },
    {
      "epoch": 1.0749724366041897,
      "grad_norm": 11.033342361450195,
      "learning_rate": 4.462513781697905e-05,
      "loss": 0.1527,
      "step": 1950
    },
    {
      "epoch": 1.1025358324145536,
      "grad_norm": 12.774890899658203,
      "learning_rate": 4.448732083792723e-05,
      "loss": 0.1539,
      "step": 2000
    },
    {
      "epoch": 1.1025358324145536,
      "eval_accuracy": 0.9379436964504284,
      "eval_loss": 0.16163066029548645,
      "eval_runtime": 72.3683,
      "eval_samples_per_second": 112.895,
      "eval_steps_per_second": 3.537,
      "step": 2000
    },
    {
      "epoch": 1.1300992282249174,
      "grad_norm": 11.11571216583252,
      "learning_rate": 4.434950385887541e-05,
      "loss": 0.1685,
      "step": 2050
    },
    {
      "epoch": 1.1576626240352812,
      "grad_norm": 21.610198974609375,
      "learning_rate": 4.4211686879823596e-05,
      "loss": 0.1386,
      "step": 2100
    },
    {
      "epoch": 1.185226019845645,
      "grad_norm": 20.331605911254883,
      "learning_rate": 4.4073869900771774e-05,
      "loss": 0.1412,
      "step": 2150
    },
    {
      "epoch": 1.2127894156560088,
      "grad_norm": 27.500516891479492,
      "learning_rate": 4.393605292171996e-05,
      "loss": 0.1447,
      "step": 2200
    },
    {
      "epoch": 1.2127894156560088,
      "eval_accuracy": 0.9285189718482252,
      "eval_loss": 0.18478555977344513,
      "eval_runtime": 67.3195,
      "eval_samples_per_second": 121.361,
      "eval_steps_per_second": 3.803,
      "step": 2200
    },
    {
      "epoch": 1.2403528114663727,
      "grad_norm": 11.57060432434082,
      "learning_rate": 4.3798235942668137e-05,
      "loss": 0.1204,
      "step": 2250
    },
    {
      "epoch": 1.2679162072767365,
      "grad_norm": 12.228941917419434,
      "learning_rate": 4.3660418963616315e-05,
      "loss": 0.1437,
      "step": 2300
    },
    {
      "epoch": 1.2954796030871003,
      "grad_norm": 17.883207321166992,
      "learning_rate": 4.35226019845645e-05,
      "loss": 0.1549,
      "step": 2350
    },
    {
      "epoch": 1.3230429988974641,
      "grad_norm": 21.208154678344727,
      "learning_rate": 4.338478500551268e-05,
      "loss": 0.1438,
      "step": 2400
    },
    {
      "epoch": 1.3230429988974641,
      "eval_accuracy": 0.9599755201958384,
      "eval_loss": 0.10651371628046036,
      "eval_runtime": 67.8041,
      "eval_samples_per_second": 120.494,
      "eval_steps_per_second": 3.776,
      "step": 2400
    },
    {
      "epoch": 1.350606394707828,
      "grad_norm": 29.760766983032227,
      "learning_rate": 4.324696802646086e-05,
      "loss": 0.1409,
      "step": 2450
    },
    {
      "epoch": 1.3781697905181918,
      "grad_norm": 11.760438919067383,
      "learning_rate": 4.310915104740904e-05,
      "loss": 0.1196,
      "step": 2500
    },
    {
      "epoch": 1.4057331863285556,
      "grad_norm": 15.07766056060791,
      "learning_rate": 4.2971334068357225e-05,
      "loss": 0.1466,
      "step": 2550
    },
    {
      "epoch": 1.4332965821389196,
      "grad_norm": 18.95243263244629,
      "learning_rate": 4.28335170893054e-05,
      "loss": 0.1211,
      "step": 2600
    },
    {
      "epoch": 1.4332965821389196,
      "eval_accuracy": 0.8795593635250918,
      "eval_loss": 0.31819266080856323,
      "eval_runtime": 67.725,
      "eval_samples_per_second": 120.635,
      "eval_steps_per_second": 3.78,
      "step": 2600
    },
    {
      "epoch": 1.4608599779492835,
      "grad_norm": 16.635509490966797,
      "learning_rate": 4.269570011025358e-05,
      "loss": 0.1443,
      "step": 2650
    },
    {
      "epoch": 1.4884233737596473,
      "grad_norm": 5.884675025939941,
      "learning_rate": 4.2557883131201766e-05,
      "loss": 0.1213,
      "step": 2700
    },
    {
      "epoch": 1.515986769570011,
      "grad_norm": 14.835115432739258,
      "learning_rate": 4.2420066152149944e-05,
      "loss": 0.1257,
      "step": 2750
    },
    {
      "epoch": 1.543550165380375,
      "grad_norm": 17.145263671875,
      "learning_rate": 4.228224917309813e-05,
      "loss": 0.1293,
      "step": 2800
    },
    {
      "epoch": 1.543550165380375,
      "eval_accuracy": 0.9598531211750306,
      "eval_loss": 0.11314146220684052,
      "eval_runtime": 67.5715,
      "eval_samples_per_second": 120.909,
      "eval_steps_per_second": 3.789,
      "step": 2800
    },
    {
      "epoch": 1.5711135611907387,
      "grad_norm": 11.879613876342773,
      "learning_rate": 4.214443219404631e-05,
      "loss": 0.1044,
      "step": 2850
    },
    {
      "epoch": 1.5986769570011026,
      "grad_norm": 36.86888122558594,
      "learning_rate": 4.2006615214994485e-05,
      "loss": 0.1213,
      "step": 2900
    },
    {
      "epoch": 1.6262403528114664,
      "grad_norm": 17.293405532836914,
      "learning_rate": 4.186879823594267e-05,
      "loss": 0.1131,
      "step": 2950
    },
    {
      "epoch": 1.6538037486218302,
      "grad_norm": 23.07198143005371,
      "learning_rate": 4.173098125689085e-05,
      "loss": 0.1241,
      "step": 3000
    },
    {
      "epoch": 1.6538037486218302,
      "eval_accuracy": 0.9649938800489596,
      "eval_loss": 0.09814000129699707,
      "eval_runtime": 67.294,
      "eval_samples_per_second": 121.408,
      "eval_steps_per_second": 3.804,
      "step": 3000
    },
    {
      "epoch": 1.681367144432194,
      "grad_norm": 12.365978240966797,
      "learning_rate": 4.159316427783903e-05,
      "loss": 0.1096,
      "step": 3050
    },
    {
      "epoch": 1.7089305402425579,
      "grad_norm": 2.7194626331329346,
      "learning_rate": 4.145534729878721e-05,
      "loss": 0.1082,
      "step": 3100
    },
    {
      "epoch": 1.7364939360529217,
      "grad_norm": 11.97074031829834,
      "learning_rate": 4.1317530319735396e-05,
      "loss": 0.1111,
      "step": 3150
    },
    {
      "epoch": 1.7640573318632855,
      "grad_norm": 10.857202529907227,
      "learning_rate": 4.1179713340683574e-05,
      "loss": 0.1416,
      "step": 3200
    },
    {
      "epoch": 1.7640573318632855,
      "eval_accuracy": 0.957282741738066,
      "eval_loss": 0.12110248953104019,
      "eval_runtime": 68.1087,
      "eval_samples_per_second": 119.955,
      "eval_steps_per_second": 3.759,
      "step": 3200
    },
    {
      "epoch": 1.7916207276736493,
      "grad_norm": 5.398325443267822,
      "learning_rate": 4.104189636163175e-05,
      "loss": 0.1011,
      "step": 3250
    },
    {
      "epoch": 1.8191841234840131,
      "grad_norm": 21.62636947631836,
      "learning_rate": 4.0904079382579937e-05,
      "loss": 0.0981,
      "step": 3300
    },
    {
      "epoch": 1.846747519294377,
      "grad_norm": 3.0159223079681396,
      "learning_rate": 4.0766262403528115e-05,
      "loss": 0.103,
      "step": 3350
    },
    {
      "epoch": 1.8743109151047408,
      "grad_norm": 23.464122772216797,
      "learning_rate": 4.06284454244763e-05,
      "loss": 0.1188,
      "step": 3400
    },
    {
      "epoch": 1.8743109151047408,
      "eval_accuracy": 0.9577723378212974,
      "eval_loss": 0.11673861742019653,
      "eval_runtime": 70.6359,
      "eval_samples_per_second": 115.664,
      "eval_steps_per_second": 3.624,
      "step": 3400
    },
    {
      "epoch": 1.9018743109151046,
      "grad_norm": 22.30855941772461,
      "learning_rate": 4.049062844542448e-05,
      "loss": 0.0975,
      "step": 3450
    },
    {
      "epoch": 1.9294377067254684,
      "grad_norm": 18.873004913330078,
      "learning_rate": 4.0352811466372656e-05,
      "loss": 0.1173,
      "step": 3500
    },
    {
      "epoch": 1.9570011025358323,
      "grad_norm": 19.87538719177246,
      "learning_rate": 4.021499448732084e-05,
      "loss": 0.1053,
      "step": 3550
    },
    {
      "epoch": 1.9845644983461963,
      "grad_norm": 6.108936786651611,
      "learning_rate": 4.007717750826902e-05,
      "loss": 0.098,
      "step": 3600
    },
    {
      "epoch": 1.9845644983461963,
      "eval_accuracy": 0.9682986536107712,
      "eval_loss": 0.0848337933421135,
      "eval_runtime": 69.7781,
      "eval_samples_per_second": 117.085,
      "eval_steps_per_second": 3.669,
      "step": 3600
    },
    {
      "epoch": 2.01212789415656,
      "grad_norm": 3.616061210632324,
      "learning_rate": 3.99393605292172e-05,
      "loss": 0.0766,
      "step": 3650
    },
    {
      "epoch": 2.0396912899669237,
      "grad_norm": 12.557113647460938,
      "learning_rate": 3.980154355016538e-05,
      "loss": 0.106,
      "step": 3700
    },
    {
      "epoch": 2.0672546857772875,
      "grad_norm": 15.2953519821167,
      "learning_rate": 3.9663726571113566e-05,
      "loss": 0.0926,
      "step": 3750
    },
    {
      "epoch": 2.0948180815876514,
      "grad_norm": 5.290070056915283,
      "learning_rate": 3.9525909592061744e-05,
      "loss": 0.0745,
      "step": 3800
    },
    {
      "epoch": 2.0948180815876514,
      "eval_accuracy": 0.9692778457772337,
      "eval_loss": 0.08135415613651276,
      "eval_runtime": 68.734,
      "eval_samples_per_second": 118.864,
      "eval_steps_per_second": 3.725,
      "step": 3800
    },
    {
      "epoch": 2.1223814773980156,
      "grad_norm": 26.75394058227539,
      "learning_rate": 3.938809261300992e-05,
      "loss": 0.0805,
      "step": 3850
    },
    {
      "epoch": 2.1499448732083795,
      "grad_norm": 23.23959732055664,
      "learning_rate": 3.925027563395811e-05,
      "loss": 0.0911,
      "step": 3900
    },
    {
      "epoch": 2.1775082690187433,
      "grad_norm": 14.778151512145996,
      "learning_rate": 3.9112458654906285e-05,
      "loss": 0.0964,
      "step": 3950
    },
    {
      "epoch": 2.205071664829107,
      "grad_norm": 22.820573806762695,
      "learning_rate": 3.897464167585447e-05,
      "loss": 0.0992,
      "step": 4000
    },
    {
      "epoch": 2.205071664829107,
      "eval_accuracy": 0.9685434516523868,
      "eval_loss": 0.08866504579782486,
      "eval_runtime": 67.5747,
      "eval_samples_per_second": 120.903,
      "eval_steps_per_second": 3.788,
      "step": 4000
    },
    {
      "epoch": 2.232635060639471,
      "grad_norm": 9.064249992370605,
      "learning_rate": 3.883682469680265e-05,
      "loss": 0.0673,
      "step": 4050
    },
    {
      "epoch": 2.2601984564498347,
      "grad_norm": 15.528149604797363,
      "learning_rate": 3.8699007717750826e-05,
      "loss": 0.0741,
      "step": 4100
    },
    {
      "epoch": 2.2877618522601986,
      "grad_norm": 28.561437606811523,
      "learning_rate": 3.856119073869901e-05,
      "loss": 0.0661,
      "step": 4150
    },
    {
      "epoch": 2.3153252480705624,
      "grad_norm": 2.754340410232544,
      "learning_rate": 3.842337375964719e-05,
      "loss": 0.0893,
      "step": 4200
    },
    {
      "epoch": 2.3153252480705624,
      "eval_accuracy": 0.9751529987760098,
      "eval_loss": 0.07494325190782547,
      "eval_runtime": 68.9526,
      "eval_samples_per_second": 118.487,
      "eval_steps_per_second": 3.713,
      "step": 4200
    },
    {
      "epoch": 2.342888643880926,
      "grad_norm": 16.55693817138672,
      "learning_rate": 3.8285556780595374e-05,
      "loss": 0.0936,
      "step": 4250
    },
    {
      "epoch": 2.37045203969129,
      "grad_norm": 4.099716663360596,
      "learning_rate": 3.814773980154355e-05,
      "loss": 0.0762,
      "step": 4300
    },
    {
      "epoch": 2.398015435501654,
      "grad_norm": 2.4832441806793213,
      "learning_rate": 3.8009922822491737e-05,
      "loss": 0.0561,
      "step": 4350
    },
    {
      "epoch": 2.4255788313120177,
      "grad_norm": 13.325751304626465,
      "learning_rate": 3.7872105843439915e-05,
      "loss": 0.0703,
      "step": 4400
    },
    {
      "epoch": 2.4255788313120177,
      "eval_accuracy": 0.964749082007344,
      "eval_loss": 0.09584648907184601,
      "eval_runtime": 70.4496,
      "eval_samples_per_second": 115.969,
      "eval_steps_per_second": 3.634,
      "step": 4400
    },
    {
      "epoch": 2.4531422271223815,
      "grad_norm": 2.894495964050293,
      "learning_rate": 3.773428886438809e-05,
      "loss": 0.0735,
      "step": 4450
    },
    {
      "epoch": 2.4807056229327453,
      "grad_norm": 8.077949523925781,
      "learning_rate": 3.759647188533628e-05,
      "loss": 0.1038,
      "step": 4500
    },
    {
      "epoch": 2.508269018743109,
      "grad_norm": 35.674415588378906,
      "learning_rate": 3.7458654906284456e-05,
      "loss": 0.0903,
      "step": 4550
    },
    {
      "epoch": 2.535832414553473,
      "grad_norm": 7.038674354553223,
      "learning_rate": 3.732083792723264e-05,
      "loss": 0.1216,
      "step": 4600
    },
    {
      "epoch": 2.535832414553473,
      "eval_accuracy": 0.9718482252141983,
      "eval_loss": 0.07874296605587006,
      "eval_runtime": 67.8315,
      "eval_samples_per_second": 120.446,
      "eval_steps_per_second": 3.774,
      "step": 4600
    },
    {
      "epoch": 2.563395810363837,
      "grad_norm": 21.762752532958984,
      "learning_rate": 3.718302094818082e-05,
      "loss": 0.0488,
      "step": 4650
    },
    {
      "epoch": 2.5909592061742006,
      "grad_norm": 10.72203254699707,
      "learning_rate": 3.7045203969128996e-05,
      "loss": 0.0686,
      "step": 4700
    },
    {
      "epoch": 2.6185226019845644,
      "grad_norm": 8.018559455871582,
      "learning_rate": 3.690738699007718e-05,
      "loss": 0.0739,
      "step": 4750
    },
    {
      "epoch": 2.6460859977949283,
      "grad_norm": 8.183494567871094,
      "learning_rate": 3.676957001102536e-05,
      "loss": 0.0618,
      "step": 4800
    },
    {
      "epoch": 2.6460859977949283,
      "eval_accuracy": 0.9692778457772337,
      "eval_loss": 0.07761503756046295,
      "eval_runtime": 69.6937,
      "eval_samples_per_second": 117.227,
      "eval_steps_per_second": 3.673,
      "step": 4800
    },
    {
      "epoch": 2.673649393605292,
      "grad_norm": 20.75224494934082,
      "learning_rate": 3.6631753031973544e-05,
      "loss": 0.0806,
      "step": 4850
    },
    {
      "epoch": 2.701212789415656,
      "grad_norm": 3.843508243560791,
      "learning_rate": 3.649393605292172e-05,
      "loss": 0.0688,
      "step": 4900
    },
    {
      "epoch": 2.7287761852260197,
      "grad_norm": 15.64573860168457,
      "learning_rate": 3.635611907386991e-05,
      "loss": 0.0972,
      "step": 4950
    },
    {
      "epoch": 2.7563395810363835,
      "grad_norm": 29.360862731933594,
      "learning_rate": 3.6218302094818085e-05,
      "loss": 0.0612,
      "step": 5000
    },
    {
      "epoch": 2.7563395810363835,
      "eval_accuracy": 0.9625458996328029,
      "eval_loss": 0.09516000747680664,
      "eval_runtime": 70.665,
      "eval_samples_per_second": 115.616,
      "eval_steps_per_second": 3.623,
      "step": 5000
    },
    {
      "epoch": 2.7839029768467474,
      "grad_norm": 0.3797323405742645,
      "learning_rate": 3.608048511576626e-05,
      "loss": 0.0746,
      "step": 5050
    },
    {
      "epoch": 2.811466372657111,
      "grad_norm": 4.315881729125977,
      "learning_rate": 3.594266813671445e-05,
      "loss": 0.056,
      "step": 5100
    },
    {
      "epoch": 2.8390297684674755,
      "grad_norm": 4.7198686599731445,
      "learning_rate": 3.5804851157662626e-05,
      "loss": 0.0662,
      "step": 5150
    },
    {
      "epoch": 2.8665931642778393,
      "grad_norm": 15.324909210205078,
      "learning_rate": 3.566703417861081e-05,
      "loss": 0.0632,
      "step": 5200
    },
    {
      "epoch": 2.8665931642778393,
      "eval_accuracy": 0.9720930232558139,
      "eval_loss": 0.0731869637966156,
      "eval_runtime": 69.4896,
      "eval_samples_per_second": 117.571,
      "eval_steps_per_second": 3.684,
      "step": 5200
    },
    {
      "epoch": 2.894156560088203,
      "grad_norm": 4.856844425201416,
      "learning_rate": 3.552921719955899e-05,
      "loss": 0.0673,
      "step": 5250
    },
    {
      "epoch": 2.921719955898567,
      "grad_norm": 17.418685913085938,
      "learning_rate": 3.5391400220507174e-05,
      "loss": 0.0747,
      "step": 5300
    },
    {
      "epoch": 2.9492833517089307,
      "grad_norm": 1.5806334018707275,
      "learning_rate": 3.525358324145535e-05,
      "loss": 0.0707,
      "step": 5350
    },
    {
      "epoch": 2.9768467475192946,
      "grad_norm": 16.916793823242188,
      "learning_rate": 3.511576626240353e-05,
      "loss": 0.0555,
      "step": 5400
    },
    {
      "epoch": 2.9768467475192946,
      "eval_accuracy": 0.9767441860465116,
      "eval_loss": 0.07163648307323456,
      "eval_runtime": 68.8747,
      "eval_samples_per_second": 118.621,
      "eval_steps_per_second": 3.717,
      "step": 5400
    },
    {
      "epoch": 3.0044101433296584,
      "grad_norm": 6.508782386779785,
      "learning_rate": 3.4977949283351715e-05,
      "loss": 0.0534,
      "step": 5450
    },
    {
      "epoch": 3.031973539140022,
      "grad_norm": 7.1942219734191895,
      "learning_rate": 3.484013230429989e-05,
      "loss": 0.0698,
      "step": 5500
    },
    {
      "epoch": 3.059536934950386,
      "grad_norm": 17.76059341430664,
      "learning_rate": 3.470231532524808e-05,
      "loss": 0.0765,
      "step": 5550
    },
    {
      "epoch": 3.08710033076075,
      "grad_norm": 0.30658018589019775,
      "learning_rate": 3.4564498346196256e-05,
      "loss": 0.061,
      "step": 5600
    },
    {
      "epoch": 3.08710033076075,
      "eval_accuracy": 0.9777233782129743,
      "eval_loss": 0.05890481919050217,
      "eval_runtime": 69.7949,
      "eval_samples_per_second": 117.057,
      "eval_steps_per_second": 3.668,
      "step": 5600
    },
    {
      "epoch": 3.1146637265711137,
      "grad_norm": 15.532384872436523,
      "learning_rate": 3.4426681367144434e-05,
      "loss": 0.0446,
      "step": 5650
    },
    {
      "epoch": 3.1422271223814775,
      "grad_norm": 23.895971298217773,
      "learning_rate": 3.428886438809261e-05,
      "loss": 0.0584,
      "step": 5700
    },
    {
      "epoch": 3.1697905181918413,
      "grad_norm": 0.9480639696121216,
      "learning_rate": 3.415104740904079e-05,
      "loss": 0.0469,
      "step": 5750
    },
    {
      "epoch": 3.197353914002205,
      "grad_norm": 7.112790107727051,
      "learning_rate": 3.4013230429988975e-05,
      "loss": 0.0515,
      "step": 5800
    },
    {
      "epoch": 3.197353914002205,
      "eval_accuracy": 0.9785801713586292,
      "eval_loss": 0.05922519043087959,
      "eval_runtime": 70.5525,
      "eval_samples_per_second": 115.8,
      "eval_steps_per_second": 3.629,
      "step": 5800
    },
    {
      "epoch": 3.224917309812569,
      "grad_norm": 27.64832305908203,
      "learning_rate": 3.387541345093715e-05,
      "loss": 0.0641,
      "step": 5850
    },
    {
      "epoch": 3.252480705622933,
      "grad_norm": 3.7776618003845215,
      "learning_rate": 3.373759647188534e-05,
      "loss": 0.0561,
      "step": 5900
    },
    {
      "epoch": 3.2800441014332966,
      "grad_norm": 16.953088760375977,
      "learning_rate": 3.3599779492833515e-05,
      "loss": 0.0443,
      "step": 5950
    },
    {
      "epoch": 3.3076074972436604,
      "grad_norm": 8.5817232131958,
      "learning_rate": 3.34619625137817e-05,
      "loss": 0.0755,
      "step": 6000
    },
    {
      "epoch": 3.3076074972436604,
      "eval_accuracy": 0.9700122399020807,
      "eval_loss": 0.07564771920442581,
      "eval_runtime": 67.0003,
      "eval_samples_per_second": 121.94,
      "eval_steps_per_second": 3.821,
      "step": 6000
    },
    {
      "epoch": 3.3351708930540243,
      "grad_norm": 31.604202270507812,
      "learning_rate": 3.332414553472988e-05,
      "loss": 0.0447,
      "step": 6050
    },
    {
      "epoch": 3.362734288864388,
      "grad_norm": 27.55440330505371,
      "learning_rate": 3.3186328555678056e-05,
      "loss": 0.042,
      "step": 6100
    },
    {
      "epoch": 3.390297684674752,
      "grad_norm": 12.801488876342773,
      "learning_rate": 3.304851157662624e-05,
      "loss": 0.0667,
      "step": 6150
    },
    {
      "epoch": 3.4178610804851157,
      "grad_norm": 9.159116744995117,
      "learning_rate": 3.291069459757442e-05,
      "loss": 0.0506,
      "step": 6200
    },
    {
      "epoch": 3.4178610804851157,
      "eval_accuracy": 0.9730722154222766,
      "eval_loss": 0.07842814922332764,
      "eval_runtime": 67.1764,
      "eval_samples_per_second": 121.62,
      "eval_steps_per_second": 3.811,
      "step": 6200
    },
    {
      "epoch": 3.4454244762954795,
      "grad_norm": 5.219883441925049,
      "learning_rate": 3.2772877618522604e-05,
      "loss": 0.0636,
      "step": 6250
    },
    {
      "epoch": 3.4729878721058434,
      "grad_norm": 10.33033275604248,
      "learning_rate": 3.263506063947078e-05,
      "loss": 0.0523,
      "step": 6300
    },
    {
      "epoch": 3.500551267916207,
      "grad_norm": 44.30976486206055,
      "learning_rate": 3.249724366041896e-05,
      "loss": 0.0624,
      "step": 6350
    },
    {
      "epoch": 3.528114663726571,
      "grad_norm": 25.22199821472168,
      "learning_rate": 3.2359426681367145e-05,
      "loss": 0.0433,
      "step": 6400
    },
    {
      "epoch": 3.528114663726571,
      "eval_accuracy": 0.9755201958384333,
      "eval_loss": 0.0730137825012207,
      "eval_runtime": 68.1116,
      "eval_samples_per_second": 119.95,
      "eval_steps_per_second": 3.759,
      "step": 6400
    },
    {
      "epoch": 3.555678059536935,
      "grad_norm": 9.718583106994629,
      "learning_rate": 3.222160970231532e-05,
      "loss": 0.0463,
      "step": 6450
    },
    {
      "epoch": 3.5832414553472987,
      "grad_norm": 12.73061466217041,
      "learning_rate": 3.208379272326351e-05,
      "loss": 0.0456,
      "step": 6500
    },
    {
      "epoch": 3.6108048511576625,
      "grad_norm": 30.594636917114258,
      "learning_rate": 3.1945975744211686e-05,
      "loss": 0.0446,
      "step": 6550
    },
    {
      "epoch": 3.6383682469680263,
      "grad_norm": 0.2015867978334427,
      "learning_rate": 3.180815876515987e-05,
      "loss": 0.0642,
      "step": 6600
    },
    {
      "epoch": 3.6383682469680263,
      "eval_accuracy": 0.9762545899632803,
      "eval_loss": 0.08209025114774704,
      "eval_runtime": 69.5458,
      "eval_samples_per_second": 117.476,
      "eval_steps_per_second": 3.681,
      "step": 6600
    },
    {
      "epoch": 3.66593164277839,
      "grad_norm": 2.4976844787597656,
      "learning_rate": 3.167034178610805e-05,
      "loss": 0.0355,
      "step": 6650
    },
    {
      "epoch": 3.693495038588754,
      "grad_norm": 2.024817943572998,
      "learning_rate": 3.153252480705623e-05,
      "loss": 0.0482,
      "step": 6700
    },
    {
      "epoch": 3.7210584343991178,
      "grad_norm": 1.6799933910369873,
      "learning_rate": 3.139470782800441e-05,
      "loss": 0.0541,
      "step": 6750
    },
    {
      "epoch": 3.7486218302094816,
      "grad_norm": 9.261614799499512,
      "learning_rate": 3.125689084895259e-05,
      "loss": 0.0773,
      "step": 6800
    },
    {
      "epoch": 3.7486218302094816,
      "eval_accuracy": 0.9763769889840881,
      "eval_loss": 0.06878793239593506,
      "eval_runtime": 70.8366,
      "eval_samples_per_second": 115.336,
      "eval_steps_per_second": 3.614,
      "step": 6800
    },
    {
      "epoch": 3.7761852260198454,
      "grad_norm": 9.743239402770996,
      "learning_rate": 3.1119073869900775e-05,
      "loss": 0.0433,
      "step": 6850
    },
    {
      "epoch": 3.8037486218302092,
      "grad_norm": 9.740549087524414,
      "learning_rate": 3.098125689084895e-05,
      "loss": 0.0419,
      "step": 6900
    },
    {
      "epoch": 3.831312017640573,
      "grad_norm": 1.1351689100265503,
      "learning_rate": 3.084343991179713e-05,
      "loss": 0.0495,
      "step": 6950
    },
    {
      "epoch": 3.8588754134509373,
      "grad_norm": 0.2783712148666382,
      "learning_rate": 3.0705622932745315e-05,
      "loss": 0.0398,
      "step": 7000
    },
    {
      "epoch": 3.8588754134509373,
      "eval_accuracy": 0.980171358629131,
      "eval_loss": 0.05529350787401199,
      "eval_runtime": 69.1905,
      "eval_samples_per_second": 118.08,
      "eval_steps_per_second": 3.7,
      "step": 7000
    },
    {
      "epoch": 3.886438809261301,
      "grad_norm": 1.0637391805648804,
      "learning_rate": 3.0567805953693494e-05,
      "loss": 0.0455,
      "step": 7050
    },
    {
      "epoch": 3.914002205071665,
      "grad_norm": 13.528304100036621,
      "learning_rate": 3.0429988974641675e-05,
      "loss": 0.0329,
      "step": 7100
    },
    {
      "epoch": 3.941565600882029,
      "grad_norm": 8.152507781982422,
      "learning_rate": 3.0292171995589856e-05,
      "loss": 0.0479,
      "step": 7150
    },
    {
      "epoch": 3.9691289966923926,
      "grad_norm": 4.143534183502197,
      "learning_rate": 3.0154355016538038e-05,
      "loss": 0.0376,
      "step": 7200
    },
    {
      "epoch": 3.9691289966923926,
      "eval_accuracy": 0.9807833537331702,
      "eval_loss": 0.05138474330306053,
      "eval_runtime": 71.5723,
      "eval_samples_per_second": 114.15,
      "eval_steps_per_second": 3.577,
      "step": 7200
    },
    {
      "epoch": 3.9966923925027564,
      "grad_norm": 7.24449348449707,
      "learning_rate": 3.001653803748622e-05,
      "loss": 0.0457,
      "step": 7250
    },
    {
      "epoch": 4.02425578831312,
      "grad_norm": 4.6447062492370605,
      "learning_rate": 2.98787210584344e-05,
      "loss": 0.0545,
      "step": 7300
    },
    {
      "epoch": 4.051819184123484,
      "grad_norm": 3.896643877029419,
      "learning_rate": 2.9740904079382582e-05,
      "loss": 0.0481,
      "step": 7350
    },
    {
      "epoch": 4.0793825799338475,
      "grad_norm": 10.668733596801758,
      "learning_rate": 2.9603087100330764e-05,
      "loss": 0.04,
      "step": 7400
    },
    {
      "epoch": 4.0793825799338475,
      "eval_accuracy": 0.9810281517747858,
      "eval_loss": 0.057740021497011185,
      "eval_runtime": 70.8752,
      "eval_samples_per_second": 115.273,
      "eval_steps_per_second": 3.612,
      "step": 7400
    },
    {
      "epoch": 4.106945975744211,
      "grad_norm": 2.3681130409240723,
      "learning_rate": 2.946527012127894e-05,
      "loss": 0.0227,
      "step": 7450
    },
    {
      "epoch": 4.134509371554575,
      "grad_norm": 13.872720718383789,
      "learning_rate": 2.9327453142227123e-05,
      "loss": 0.0444,
      "step": 7500
    },
    {
      "epoch": 4.16207276736494,
      "grad_norm": 0.14902378618717194,
      "learning_rate": 2.9189636163175304e-05,
      "loss": 0.0417,
      "step": 7550
    },
    {
      "epoch": 4.189636163175303,
      "grad_norm": 4.8859100341796875,
      "learning_rate": 2.9051819184123486e-05,
      "loss": 0.0353,
      "step": 7600
    },
    {
      "epoch": 4.189636163175303,
      "eval_accuracy": 0.9753977968176255,
      "eval_loss": 0.07280796021223068,
      "eval_runtime": 71.9791,
      "eval_samples_per_second": 113.505,
      "eval_steps_per_second": 3.557,
      "step": 7600
    },
    {
      "epoch": 4.2171995589856675,
      "grad_norm": 0.3356766104698181,
      "learning_rate": 2.8914002205071667e-05,
      "loss": 0.0624,
      "step": 7650
    },
    {
      "epoch": 4.244762954796031,
      "grad_norm": 0.8245267868041992,
      "learning_rate": 2.877618522601985e-05,
      "loss": 0.0297,
      "step": 7700
    },
    {
      "epoch": 4.272326350606395,
      "grad_norm": 17.629661560058594,
      "learning_rate": 2.8638368246968027e-05,
      "loss": 0.0374,
      "step": 7750
    },
    {
      "epoch": 4.299889746416759,
      "grad_norm": 10.329195022583008,
      "learning_rate": 2.8500551267916208e-05,
      "loss": 0.045,
      "step": 7800
    },
    {
      "epoch": 4.299889746416759,
      "eval_accuracy": 0.9739290085679314,
      "eval_loss": 0.0748395323753357,
      "eval_runtime": 70.0023,
      "eval_samples_per_second": 116.71,
      "eval_steps_per_second": 3.657,
      "step": 7800
    },
    {
      "epoch": 4.327453142227123,
      "grad_norm": 1.110831618309021,
      "learning_rate": 2.836273428886439e-05,
      "loss": 0.0426,
      "step": 7850
    },
    {
      "epoch": 4.355016538037487,
      "grad_norm": 27.457378387451172,
      "learning_rate": 2.822491730981257e-05,
      "loss": 0.0326,
      "step": 7900
    },
    {
      "epoch": 4.38257993384785,
      "grad_norm": 0.6708653569221497,
      "learning_rate": 2.8087100330760753e-05,
      "loss": 0.0455,
      "step": 7950
    },
    {
      "epoch": 4.410143329658214,
      "grad_norm": 7.11838436126709,
      "learning_rate": 2.7949283351708934e-05,
      "loss": 0.0375,
      "step": 8000
    },
    {
      "epoch": 4.410143329658214,
      "eval_accuracy": 0.9840881272949816,
      "eval_loss": 0.039860595017671585,
      "eval_runtime": 67.8197,
      "eval_samples_per_second": 120.466,
      "eval_steps_per_second": 3.775,
      "step": 8000
    },
    {
      "epoch": 4.437706725468578,
      "grad_norm": 27.428611755371094,
      "learning_rate": 2.7811466372657112e-05,
      "loss": 0.0245,
      "step": 8050
    },
    {
      "epoch": 4.465270121278942,
      "grad_norm": 2.384819746017456,
      "learning_rate": 2.7673649393605294e-05,
      "loss": 0.0331,
      "step": 8100
    },
    {
      "epoch": 4.492833517089306,
      "grad_norm": 3.040158748626709,
      "learning_rate": 2.7535832414553475e-05,
      "loss": 0.0388,
      "step": 8150
    },
    {
      "epoch": 4.5203969128996695,
      "grad_norm": 14.702971458435059,
      "learning_rate": 2.7398015435501656e-05,
      "loss": 0.0514,
      "step": 8200
    },
    {
      "epoch": 4.5203969128996695,
      "eval_accuracy": 0.9784577723378213,
      "eval_loss": 0.071449875831604,
      "eval_runtime": 69.2257,
      "eval_samples_per_second": 118.02,
      "eval_steps_per_second": 3.698,
      "step": 8200
    },
    {
      "epoch": 4.547960308710033,
      "grad_norm": 14.242265701293945,
      "learning_rate": 2.7260198456449838e-05,
      "loss": 0.054,
      "step": 8250
    },
    {
      "epoch": 4.575523704520397,
      "grad_norm": 4.951054573059082,
      "learning_rate": 2.712238147739802e-05,
      "loss": 0.0241,
      "step": 8300
    },
    {
      "epoch": 4.603087100330761,
      "grad_norm": 66.74259185791016,
      "learning_rate": 2.6984564498346197e-05,
      "loss": 0.0441,
      "step": 8350
    },
    {
      "epoch": 4.630650496141125,
      "grad_norm": 0.9136132001876831,
      "learning_rate": 2.684674751929438e-05,
      "loss": 0.0294,
      "step": 8400
    },
    {
      "epoch": 4.630650496141125,
      "eval_accuracy": 0.9795593635250918,
      "eval_loss": 0.07126786559820175,
      "eval_runtime": 69.8532,
      "eval_samples_per_second": 116.96,
      "eval_steps_per_second": 3.665,
      "step": 8400
    },
    {
      "epoch": 4.658213891951489,
      "grad_norm": 37.875240325927734,
      "learning_rate": 2.670893054024256e-05,
      "loss": 0.0334,
      "step": 8450
    },
    {
      "epoch": 4.685777287761852,
      "grad_norm": 0.31828269362449646,
      "learning_rate": 2.657111356119074e-05,
      "loss": 0.0331,
      "step": 8500
    },
    {
      "epoch": 4.713340683572216,
      "grad_norm": 0.03757571801543236,
      "learning_rate": 2.6433296582138923e-05,
      "loss": 0.0297,
      "step": 8550
    },
    {
      "epoch": 4.74090407938258,
      "grad_norm": 3.3217897415161133,
      "learning_rate": 2.6295479603087105e-05,
      "loss": 0.0246,
      "step": 8600
    },
    {
      "epoch": 4.74090407938258,
      "eval_accuracy": 0.9746634026927785,
      "eval_loss": 0.07974942028522491,
      "eval_runtime": 70.1201,
      "eval_samples_per_second": 116.514,
      "eval_steps_per_second": 3.651,
      "step": 8600
    },
    {
      "epoch": 4.768467475192944,
      "grad_norm": 0.37029725313186646,
      "learning_rate": 2.6157662624035283e-05,
      "loss": 0.04,
      "step": 8650
    },
    {
      "epoch": 4.796030871003308,
      "grad_norm": 18.30963134765625,
      "learning_rate": 2.6019845644983464e-05,
      "loss": 0.0288,
      "step": 8700
    },
    {
      "epoch": 4.8235942668136715,
      "grad_norm": 1.1066300868988037,
      "learning_rate": 2.5882028665931645e-05,
      "loss": 0.0339,
      "step": 8750
    },
    {
      "epoch": 4.851157662624035,
      "grad_norm": 1.3794831037521362,
      "learning_rate": 2.5744211686879827e-05,
      "loss": 0.0316,
      "step": 8800
    },
    {
      "epoch": 4.851157662624035,
      "eval_accuracy": 0.9834761321909424,
      "eval_loss": 0.05216165632009506,
      "eval_runtime": 71.7343,
      "eval_samples_per_second": 113.892,
      "eval_steps_per_second": 3.569,
      "step": 8800
    },
    {
      "epoch": 4.878721058434399,
      "grad_norm": 0.7723345160484314,
      "learning_rate": 2.5606394707828008e-05,
      "loss": 0.0243,
      "step": 8850
    },
    {
      "epoch": 4.906284454244763,
      "grad_norm": 0.2815847098827362,
      "learning_rate": 2.546857772877619e-05,
      "loss": 0.0188,
      "step": 8900
    },
    {
      "epoch": 4.933847850055127,
      "grad_norm": 0.6836937069892883,
      "learning_rate": 2.5330760749724368e-05,
      "loss": 0.0332,
      "step": 8950
    },
    {
      "epoch": 4.961411245865491,
      "grad_norm": 24.58324432373047,
      "learning_rate": 2.519294377067255e-05,
      "loss": 0.0393,
      "step": 9000
    },
    {
      "epoch": 4.961411245865491,
      "eval_accuracy": 0.9831089351285189,
      "eval_loss": 0.05357028543949127,
      "eval_runtime": 71.7245,
      "eval_samples_per_second": 113.908,
      "eval_steps_per_second": 3.569,
      "step": 9000
    },
    {
      "epoch": 4.9889746416758545,
      "grad_norm": 1.0496459007263184,
      "learning_rate": 2.505512679162073e-05,
      "loss": 0.025,
      "step": 9050
    },
    {
      "epoch": 5.016538037486218,
      "grad_norm": 1.940204381942749,
      "learning_rate": 2.491730981256891e-05,
      "loss": 0.0494,
      "step": 9100
    },
    {
      "epoch": 5.044101433296582,
      "grad_norm": 1.594414472579956,
      "learning_rate": 2.477949283351709e-05,
      "loss": 0.0191,
      "step": 9150
    },
    {
      "epoch": 5.071664829106946,
      "grad_norm": 2.344139337539673,
      "learning_rate": 2.464167585446527e-05,
      "loss": 0.0285,
      "step": 9200
    },
    {
      "epoch": 5.071664829106946,
      "eval_accuracy": 0.9783353733170135,
      "eval_loss": 0.07425329834222794,
      "eval_runtime": 70.663,
      "eval_samples_per_second": 115.619,
      "eval_steps_per_second": 3.623,
      "step": 9200
    },
    {
      "epoch": 5.09922822491731,
      "grad_norm": 0.2468443065881729,
      "learning_rate": 2.4503858875413453e-05,
      "loss": 0.0262,
      "step": 9250
    },
    {
      "epoch": 5.126791620727674,
      "grad_norm": 1.390579104423523,
      "learning_rate": 2.436604189636163e-05,
      "loss": 0.0366,
      "step": 9300
    },
    {
      "epoch": 5.154355016538037,
      "grad_norm": 0.8086108565330505,
      "learning_rate": 2.4228224917309813e-05,
      "loss": 0.0269,
      "step": 9350
    },
    {
      "epoch": 5.181918412348401,
      "grad_norm": 5.31113862991333,
      "learning_rate": 2.4090407938257994e-05,
      "loss": 0.0389,
      "step": 9400
    },
    {
      "epoch": 5.181918412348401,
      "eval_accuracy": 0.9660954712362301,
      "eval_loss": 0.14432087540626526,
      "eval_runtime": 72.4148,
      "eval_samples_per_second": 112.822,
      "eval_steps_per_second": 3.535,
      "step": 9400
    },
    {
      "epoch": 5.209481808158765,
      "grad_norm": 1.9758470058441162,
      "learning_rate": 2.3952590959206175e-05,
      "loss": 0.0362,
      "step": 9450
    },
    {
      "epoch": 5.237045203969129,
      "grad_norm": 1.6524211168289185,
      "learning_rate": 2.3814773980154357e-05,
      "loss": 0.034,
      "step": 9500
    },
    {
      "epoch": 5.264608599779493,
      "grad_norm": 42.285743713378906,
      "learning_rate": 2.3676957001102538e-05,
      "loss": 0.0231,
      "step": 9550
    },
    {
      "epoch": 5.2921719955898565,
      "grad_norm": 4.449106693267822,
      "learning_rate": 2.353914002205072e-05,
      "loss": 0.0219,
      "step": 9600
    },
    {
      "epoch": 5.2921719955898565,
      "eval_accuracy": 0.9826193390452876,
      "eval_loss": 0.054831404238939285,
      "eval_runtime": 69.5269,
      "eval_samples_per_second": 117.508,
      "eval_steps_per_second": 3.682,
      "step": 9600
    },
    {
      "epoch": 5.31973539140022,
      "grad_norm": 1.4033048152923584,
      "learning_rate": 1.2001890061426997e-05,
      "loss": 0.021,
      "step": 9650
    },
    {
      "epoch": 5.347298787210584,
      "grad_norm": 0.03490903228521347,
      "learning_rate": 1.1805008662781541e-05,
      "loss": 0.0318,
      "step": 9700
    },
    {
      "epoch": 5.374862183020948,
      "grad_norm": 10.145513534545898,
      "learning_rate": 1.1608127264136085e-05,
      "loss": 0.0207,
      "step": 9750
    },
    {
      "epoch": 5.402425578831312,
      "grad_norm": 0.004819009453058243,
      "learning_rate": 1.1411245865490629e-05,
      "loss": 0.0207,
      "step": 9800
    },
    {
      "epoch": 5.402425578831312,
      "eval_accuracy": 0.9840881272949816,
      "eval_loss": 0.047938551753759384,
      "eval_runtime": 67.9635,
      "eval_samples_per_second": 120.212,
      "eval_steps_per_second": 3.767,
      "step": 9800
    },
    {
      "epoch": 5.429988974641676,
      "grad_norm": 39.32118225097656,
      "learning_rate": 1.1214364466845172e-05,
      "loss": 0.0151,
      "step": 9850
    },
    {
      "epoch": 5.4575523704520394,
      "grad_norm": 1.6229623556137085,
      "learning_rate": 1.1017483068199718e-05,
      "loss": 0.0195,
      "step": 9900
    },
    {
      "epoch": 5.485115766262403,
      "grad_norm": 0.9078558087348938,
      "learning_rate": 1.0820601669554261e-05,
      "loss": 0.0099,
      "step": 9950
    },
    {
      "epoch": 5.512679162072767,
      "grad_norm": 0.01648089848458767,
      "learning_rate": 1.0623720270908805e-05,
      "loss": 0.0088,
      "step": 10000
    },
    {
      "epoch": 5.512679162072767,
      "eval_accuracy": 0.9843329253365973,
      "eval_loss": 0.04741718992590904,
      "eval_runtime": 67.3438,
      "eval_samples_per_second": 121.318,
      "eval_steps_per_second": 3.801,
      "step": 10000
    },
    {
      "epoch": 5.540242557883131,
      "grad_norm": 0.25195664167404175,
      "learning_rate": 1.0426838872263349e-05,
      "loss": 0.0271,
      "step": 10050
    },
    {
      "epoch": 5.567805953693495,
      "grad_norm": 0.17787326872348785,
      "learning_rate": 1.0229957473617892e-05,
      "loss": 0.0132,
      "step": 10100
    },
    {
      "epoch": 5.595369349503859,
      "grad_norm": 8.17227840423584,
      "learning_rate": 1.0033076074972438e-05,
      "loss": 0.0167,
      "step": 10150
    },
    {
      "epoch": 5.622932745314222,
      "grad_norm": 44.02363204956055,
      "learning_rate": 9.83619467632698e-06,
      "loss": 0.0179,
      "step": 10200
    },
    {
      "epoch": 5.622932745314222,
      "eval_accuracy": 0.9813953488372092,
      "eval_loss": 0.07225113362073898,
      "eval_runtime": 68.6304,
      "eval_samples_per_second": 119.044,
      "eval_steps_per_second": 3.73,
      "step": 10200
    },
    {
      "epoch": 5.650496141124586,
      "grad_norm": 10.02514362335205,
      "learning_rate": 9.639313277681525e-06,
      "loss": 0.0066,
      "step": 10250
    },
    {
      "epoch": 5.67805953693495,
      "grad_norm": 2.3564982414245605,
      "learning_rate": 9.442431879036069e-06,
      "loss": 0.0127,
      "step": 10300
    },
    {
      "epoch": 5.705622932745314,
      "grad_norm": 45.82285690307617,
      "learning_rate": 9.245550480390613e-06,
      "loss": 0.0169,
      "step": 10350
    },
    {
      "epoch": 5.733186328555679,
      "grad_norm": 0.013764101080596447,
      "learning_rate": 9.048669081745158e-06,
      "loss": 0.0198,
      "step": 10400
    },
    {
      "epoch": 5.733186328555679,
      "eval_accuracy": 0.9854345165238678,
      "eval_loss": 0.0492769256234169,
      "eval_runtime": 68.6948,
      "eval_samples_per_second": 118.932,
      "eval_steps_per_second": 3.727,
      "step": 10400
    },
    {
      "epoch": 5.7607497243660415,
      "grad_norm": 0.5282713770866394,
      "learning_rate": 8.8517876830997e-06,
      "loss": 0.0171,
      "step": 10450
    },
    {
      "epoch": 5.788313120176406,
      "grad_norm": 0.13863565027713776,
      "learning_rate": 8.654906284454245e-06,
      "loss": 0.0214,
      "step": 10500
    },
    {
      "epoch": 5.815876515986769,
      "grad_norm": 0.7698619961738586,
      "learning_rate": 8.458024885808789e-06,
      "loss": 0.0183,
      "step": 10550
    },
    {
      "epoch": 5.843439911797134,
      "grad_norm": 0.21209269762039185,
      "learning_rate": 8.261143487163333e-06,
      "loss": 0.0121,
      "step": 10600
    },
    {
      "epoch": 5.843439911797134,
      "eval_accuracy": 0.9840881272949816,
      "eval_loss": 0.05081033334136009,
      "eval_runtime": 70.6749,
      "eval_samples_per_second": 115.6,
      "eval_steps_per_second": 3.622,
      "step": 10600
    },
    {
      "epoch": 5.871003307607497,
      "grad_norm": 15.7123441696167,
      "learning_rate": 8.064262088517877e-06,
      "loss": 0.0172,
      "step": 10650
    },
    {
      "epoch": 5.8985667034178615,
      "grad_norm": 0.15817411243915558,
      "learning_rate": 7.86738068987242e-06,
      "loss": 0.0176,
      "step": 10700
    },
    {
      "epoch": 5.926130099228224,
      "grad_norm": 15.890734672546387,
      "learning_rate": 7.670499291226966e-06,
      "loss": 0.0118,
      "step": 10750
    },
    {
      "epoch": 5.953693495038589,
      "grad_norm": 1.7045572996139526,
      "learning_rate": 7.473617892581509e-06,
      "loss": 0.012,
      "step": 10800
    },
    {
      "epoch": 5.953693495038589,
      "eval_accuracy": 0.987515299877601,
      "eval_loss": 0.030766436830163002,
      "eval_runtime": 68.6017,
      "eval_samples_per_second": 119.093,
      "eval_steps_per_second": 3.732,
      "step": 10800
    },
    {
      "epoch": 5.981256890848953,
      "grad_norm": 0.8400366902351379,
      "learning_rate": 7.276736493936054e-06,
      "loss": 0.0119,
      "step": 10850
    },
    {
      "epoch": 6.008820286659317,
      "grad_norm": 5.8816237449646,
      "learning_rate": 7.079855095290597e-06,
      "loss": 0.0093,
      "step": 10900
    },
    {
      "epoch": 6.036383682469681,
      "grad_norm": 25.70500946044922,
      "learning_rate": 6.882973696645141e-06,
      "loss": 0.0079,
      "step": 10950
    },
    {
      "epoch": 6.063947078280044,
      "grad_norm": 3.225240707397461,
      "learning_rate": 6.686092297999686e-06,
      "loss": 0.0094,
      "step": 11000
    },
    {
      "epoch": 6.063947078280044,
      "eval_accuracy": 0.986046511627907,
      "eval_loss": 0.04264575615525246,
      "eval_runtime": 72.3478,
      "eval_samples_per_second": 112.927,
      "eval_steps_per_second": 3.538,
      "step": 11000
    },
    {
      "epoch": 6.091510474090408,
      "grad_norm": 0.5690191388130188,
      "learning_rate": 6.4892108993542295e-06,
      "loss": 0.0115,
      "step": 11050
    },
    {
      "epoch": 6.119073869900772,
      "grad_norm": 0.008008780889213085,
      "learning_rate": 6.292329500708774e-06,
      "loss": 0.0039,
      "step": 11100
    },
    {
      "epoch": 6.146637265711136,
      "grad_norm": 0.2849857211112976,
      "learning_rate": 6.095448102063318e-06,
      "loss": 0.0117,
      "step": 11150
    },
    {
      "epoch": 6.1742006615215,
      "grad_norm": 0.03864089027047157,
      "learning_rate": 5.8985667034178614e-06,
      "loss": 0.0139,
      "step": 11200
    },
    {
      "epoch": 6.1742006615215,
      "eval_accuracy": 0.9881272949816401,
      "eval_loss": 0.033485978841781616,
      "eval_runtime": 69.9511,
      "eval_samples_per_second": 116.796,
      "eval_steps_per_second": 3.66,
      "step": 11200
    },
    {
      "epoch": 6.2017640573318635,
      "grad_norm": 1.870582938194275,
      "learning_rate": 5.701685304772406e-06,
      "loss": 0.0087,
      "step": 11250
    },
    {
      "epoch": 6.229327453142227,
      "grad_norm": 0.32408949732780457,
      "learning_rate": 5.504803906126949e-06,
      "loss": 0.0026,
      "step": 11300
    },
    {
      "epoch": 6.256890848952591,
      "grad_norm": 20.193836212158203,
      "learning_rate": 5.307922507481493e-06,
      "loss": 0.0041,
      "step": 11350
    },
    {
      "epoch": 6.284454244762955,
      "grad_norm": 0.021722910925745964,
      "learning_rate": 5.111041108836037e-06,
      "loss": 0.0055,
      "step": 11400
    },
    {
      "epoch": 6.284454244762955,
      "eval_accuracy": 0.9891064871481028,
      "eval_loss": 0.030126450583338737,
      "eval_runtime": 69.43,
      "eval_samples_per_second": 117.673,
      "eval_steps_per_second": 3.687,
      "step": 11400
    },
    {
      "epoch": 6.312017640573319,
      "grad_norm": 40.054931640625,
      "learning_rate": 4.914159710190582e-06,
      "loss": 0.0073,
      "step": 11450
    },
    {
      "epoch": 6.339581036383683,
      "grad_norm": 6.133150577545166,
      "learning_rate": 4.717278311545126e-06,
      "loss": 0.0142,
      "step": 11500
    },
    {
      "epoch": 6.3671444321940465,
      "grad_norm": 4.452325820922852,
      "learning_rate": 4.520396912899669e-06,
      "loss": 0.0063,
      "step": 11550
    },
    {
      "epoch": 6.39470782800441,
      "grad_norm": 2.194972515106201,
      "learning_rate": 4.323515514254214e-06,
      "loss": 0.0228,
      "step": 11600
    },
    {
      "epoch": 6.39470782800441,
      "eval_accuracy": 0.9851897184822521,
      "eval_loss": 0.05336739867925644,
      "eval_runtime": 73.1828,
      "eval_samples_per_second": 111.638,
      "eval_steps_per_second": 3.498,
      "step": 11600
    },
    {
      "epoch": 6.422271223814774,
      "grad_norm": 0.007574116811156273,
      "learning_rate": 4.126634115608757e-06,
      "loss": 0.0174,
      "step": 11650
    },
    {
      "epoch": 6.449834619625138,
      "grad_norm": 0.0006391131901182234,
      "learning_rate": 3.929752716963302e-06,
      "loss": 0.0086,
      "step": 11700
    },
    {
      "epoch": 6.477398015435502,
      "grad_norm": 21.758628845214844,
      "learning_rate": 3.732871318317845e-06,
      "loss": 0.0081,
      "step": 11750
    },
    {
      "epoch": 6.504961411245866,
      "grad_norm": 3.9573824405670166,
      "learning_rate": 3.5359899196723896e-06,
      "loss": 0.012,
      "step": 11800
    },
    {
      "epoch": 6.504961411245866,
      "eval_accuracy": 0.9884944920440637,
      "eval_loss": 0.029986755922436714,
      "eval_runtime": 69.8831,
      "eval_samples_per_second": 116.909,
      "eval_steps_per_second": 3.663,
      "step": 11800
    }
  ],
  "logging_steps": 50,
  "max_steps": 12698,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 7,
  "save_steps": 200,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 15,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0205607096557568e+16,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
