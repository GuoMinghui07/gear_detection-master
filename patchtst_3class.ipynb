{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I employ **PatchTST**, one of the SOTA transformer models for time series classification, using a **scratch learning strategy**. To begin, I first need to upload the series of **transformers** modules from **Hugging Face**ðŸ˜Š."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 17:30:17.749832: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from data_processer import *\n",
    "import torch\n",
    "from transformers import (\n",
    "    PatchTSTConfig, \n",
    "    PatchTSTForClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data (20nm) by using **TS_Processsor** I wrote, this module transforms the original data to the right input form that model could received, including normolizing, slicing, outlier removal, and generating Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected and removed outliers:\n",
      "File: degree_80.csv, Index: 0, Data: {'time': '2024-12-04 18:15:41.860.', '2-1[m/s^2]': 0.2266, '2-2[m/s^2]': 990.13763, '2-3[m/s^2]': -0.05433, '2-4[m/s^2]': 1016.1023, '2-5[m/s^2]': -1003.1174, '2-6[m/s^2]': 0.98538}\n",
      "File: degree_60.csv, Index: 0, Data: {'time': '2024-12-04 17:03:32.427.', '2-1[m/s^2]': -32.35963, '2-2[m/s^2]': 1.6487, '2-3[m/s^2]': 1017.5576, '2-4[m/s^2]': 1015.3014, '2-5[m/s^2]': 1004.6065, '2-6[m/s^2]': -0.18368}\n",
      "File: degree_60.csv, Index: 217296, Data: {'time': '2024-12-04 17:03:43.292.', '2-1[m/s^2]': -23.24958, '2-2[m/s^2]': -6.59387, '2-3[m/s^2]': 5.18964, '2-4[m/s^2]': -5.53556, '2-5[m/s^2]': -3.99335, '2-6[m/s^2]': -17.72532}\n",
      "File: degree_40.csv, Index: 0, Data: {'time': '2024-12-04 16:14:39.579.', '2-1[m/s^2]': 29.76894, '2-2[m/s^2]': -990.73804, '2-3[m/s^2]': 2.5759, '2-4[m/s^2]': 1015.4796, '2-5[m/s^2]': 0.23558, '2-6[m/s^2]': 0.02296}\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sequence', 'label'],\n",
      "        num_rows: 19419\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sequence', 'label'],\n",
      "        num_rows: 2734\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sequence', 'label'],\n",
      "        num_rows: 5516\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data_20nm\"\n",
    "ts_processor = TS_Processor(sequence_length=1024, stride=64, remove_extreme_values=True, iqr_threshold=7.0)\n",
    "dataset_dict = ts_processor(data_path)\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the configuration and model init!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/gpt/lib/python3.9/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "config = PatchTSTConfig(\n",
    "    num_input_channels=len(dataset_dict[\"train\"][0][\"sequence\"][0]), \n",
    "    num_targets=len(set(dataset_dict[\"train\"][\"label\"])), \n",
    "    context_length=len(dataset_dict[\"train\"][0][\"sequence\"]), \n",
    "    patch_length=16,\n",
    "    stride=16,\n",
    "    use_cls_token=True,\n",
    "    num_hidden_layers=3,\n",
    "    d_model=128,\n",
    "    num_attention_heads=4,\n",
    "    ffn_dim=512\n",
    ")\n",
    "model = PatchTSTForClassification(config=config)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_20nm\",\n",
    "    evaluation_strategy=\"steps\", \n",
    "    eval_steps=100, \n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=100,\n",
    "    load_best_model_at_end=True, \n",
    "    metric_for_best_model=\"eval_loss\", \n",
    "  #  greater_is_better=True, \n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    label_names=[\"target_values\"],\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_dict[\"train\"],\n",
    "    eval_dataset=dataset_dict[\"validation\"],\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin !!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3400' max='6070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3400/6070 42:09 < 33:07, 1.34 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.090300</td>\n",
       "      <td>1.069090</td>\n",
       "      <td>0.342356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.675600</td>\n",
       "      <td>0.540018</td>\n",
       "      <td>0.741039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.483400</td>\n",
       "      <td>0.384006</td>\n",
       "      <td>0.843819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.350763</td>\n",
       "      <td>0.854426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.362400</td>\n",
       "      <td>0.340539</td>\n",
       "      <td>0.855157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.262873</td>\n",
       "      <td>0.890636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>0.219991</td>\n",
       "      <td>0.915508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.263000</td>\n",
       "      <td>0.226372</td>\n",
       "      <td>0.908925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.203744</td>\n",
       "      <td>0.922458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.224462</td>\n",
       "      <td>0.909656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.228400</td>\n",
       "      <td>0.237069</td>\n",
       "      <td>0.907462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.230476</td>\n",
       "      <td>0.918069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.174400</td>\n",
       "      <td>0.201527</td>\n",
       "      <td>0.918435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.174400</td>\n",
       "      <td>0.201508</td>\n",
       "      <td>0.928676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.162595</td>\n",
       "      <td>0.942209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.156722</td>\n",
       "      <td>0.942575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.158633</td>\n",
       "      <td>0.943672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.132300</td>\n",
       "      <td>0.147182</td>\n",
       "      <td>0.946233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.132539</td>\n",
       "      <td>0.957937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.128848</td>\n",
       "      <td>0.952816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.112797</td>\n",
       "      <td>0.963789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.129739</td>\n",
       "      <td>0.959400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.152984</td>\n",
       "      <td>0.950256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.119962</td>\n",
       "      <td>0.962326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.102241</td>\n",
       "      <td>0.963424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.083692</td>\n",
       "      <td>0.969642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.093854</td>\n",
       "      <td>0.966715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.118138</td>\n",
       "      <td>0.956474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.064066</td>\n",
       "      <td>0.973299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.134951</td>\n",
       "      <td>0.956474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.100569</td>\n",
       "      <td>0.970007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.081281</td>\n",
       "      <td>0.969642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.109116</td>\n",
       "      <td>0.960863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>0.074181</td>\n",
       "      <td>0.975860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3400, training_loss=0.21064802495872273, metrics={'train_runtime': 2530.4332, 'train_samples_per_second': 76.742, 'train_steps_per_second': 2.399, 'total_flos': 2922028791091200.0, 'train_loss': 0.21064802495872273, 'epoch': 5.601317957166392})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the  'eval_accuracy' is up to 96%, what a nice result! hahaha!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='173' max='173' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [173/173 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10185562819242477, 'eval_accuracy': 0.9601160261058739, 'eval_runtime': 47.4063, 'eval_samples_per_second': 116.356, 'eval_steps_per_second': 3.649, 'epoch': 5.601317957166392}\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.evaluate(eval_dataset=dataset_dict[\"test\"])\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
